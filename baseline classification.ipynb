{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "yellow-thanksgiving",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./txt/КР472.txt\n",
      "./txt/КР8.txt\n",
      "./txt/КР116.txt\n",
      "./txt/КР77.txt\n",
      "./txt/КР76.txt\n",
      "./txt/КР62.txt\n",
      "./txt/КР329.txt\n",
      "./txt/КР467.txt\n",
      "./txt/КР249.txt\n",
      "./txt/КР507.txt\n",
      "./txt/КР277.txt\n",
      "./txt/КР288.txt\n",
      "./txt/КР317.txt\n",
      "./txt/КР129.txt\n",
      "./txt/КР48.txt\n",
      "./txt/КР75.txt\n",
      "./txt/КР289.txt\n",
      "./txt/КР504.txt\n",
      "./txt/КР266.txt\n",
      "./txt/КР460.txt\n",
      "./txt/КР138.txt\n",
      "./txt/КР71.txt\n",
      "./txt/КР58.txt\n",
      "./txt/КР70.txt\n",
      "./txt/КР111.txt\n",
      "./txt/КР139.txt\n",
      "./txt/КР475.txt\n",
      "./txt/КР515.txt\n",
      "./txt/КР501.txt\n",
      "./txt/КР529.txt\n",
      "./txt/КР339.txt\n",
      "./txt/КР66.txt\n",
      "./txt/КР73.txt\n",
      "./txt/КР67.txt\n",
      "./txt/КР98.txt\n",
      "./txt/КР476.txt\n",
      "./txt/КР338.txt\n",
      "./txt/КР502.txt\n",
      "./txt/КР565.txt\n",
      "./txt/КР607.txt\n",
      "./txt/КР161.txt\n",
      "./txt/КР613.txt\n",
      "./txt/КР149.txt\n",
      "./txt/КР612.txt\n",
      "./txt/КР160.txt\n",
      "./txt/КР610.txt\n",
      "./txt/КР16.txt\n",
      "./txt/КР611.txt\n",
      "./txt/КР588.txt\n",
      "./txt/КР173.txt\n",
      "./txt/КР601.txt\n",
      "./txt/КР12.txt\n",
      "./txt/КР614.txt\n",
      "./txt/КР589.txt\n",
      "./txt/КР574.txt\n",
      "./txt/КР400.txt\n",
      "./txt/КР372.txt\n",
      "./txt/КР164.txt\n",
      "./txt/КР602.txt\n",
      "./txt/КР11.txt\n",
      "./txt/КР39.txt\n",
      "./txt/КР10.txt\n",
      "./txt/КР603.txt\n",
      "./txt/КР561.txt\n",
      "./txt/КР575.txt\n",
      "./txt/КР544.txt\n",
      "./txt/КР578.txt\n",
      "./txt/КР593.txt\n",
      "./txt/КР587.txt\n",
      "./txt/КР140.txt\n",
      "./txt/КР154.txt\n",
      "./txt/КР168.txt\n",
      "./txt/КР35.txt\n",
      "./txt/КР20.txt\n",
      "./txt/КР155.txt\n",
      "./txt/КР141.txt\n",
      "./txt/КР357.txt\n",
      "./txt/КР586.txt\n",
      "./txt/КР592.txt\n",
      "./txt/КР223.txt\n",
      "./txt/КР237.txt\n",
      "./txt/КР551.txt\n",
      "./txt/КР547.txt\n",
      "./txt/КР553.txt\n",
      "./txt/КР584.txt\n",
      "./txt/КР590.txt\n",
      "./txt/КР341.txt\n",
      "./txt/КР396.txt\n",
      "./txt/КР157.txt\n",
      "./txt/КР143.txt\n",
      "./txt/КР36.txt\n",
      "./txt/КР23.txt\n",
      "./txt/КР142.txt\n",
      "./txt/КР156.txt\n",
      "./txt/КР591.txt\n",
      "./txt/КР234.txt\n",
      "./txt/КР546.txt\n",
      "./txt/КР541.txt\n",
      "./txt/КР151.txt\n",
      "./txt/КР30.txt\n",
      "./txt/КР193.txt\n",
      "./txt/КР31.txt\n",
      "./txt/КР150.txt\n",
      "./txt/КР144.txt\n",
      "./txt/КР178.txt\n",
      "./txt/КР346.txt\n",
      "./txt/КР255.txt\n",
      "./txt/КР335.txt\n",
      "./txt/КР123.txt\n",
      "./txt/КР137.txt\n",
      "./txt/КР1.txt\n",
      "./txt/КР95.txt\n",
      "./txt/КР43.txt\n",
      "./txt/КР94.txt\n",
      "./txt/КР80.txt\n",
      "./txt/КР136.txt\n",
      "./txt/КР283.txt\n",
      "./txt/КР297.txt\n",
      "./txt/КР526.txt\n",
      "./txt/КР532.txt\n",
      "./txt/КР450.txt\n",
      "./txt/КР336.txt\n",
      "./txt/КР134.txt\n",
      "./txt/КР120.txt\n",
      "./txt/КР69.txt\n",
      "./txt/КР68.txt\n",
      "./txt/КР3.txt\n",
      "./txt/КР135.txt\n",
      "./txt/КР337.txt\n",
      "./txt/КР294.txt\n",
      "./txt/КР535.txt\n",
      "./txt/КР284.txt\n",
      "./txt/КР290.txt\n",
      "./txt/КР496.txt\n",
      "./txt/КР7.txt\n",
      "./txt/КР93.txt\n",
      "./txt/КР50.txt\n",
      "./txt/КР44.txt\n",
      "./txt/КР78.txt\n",
      "./txt/КР79.txt\n",
      "./txt/КР45.txt\n",
      "./txt/КР51.txt\n",
      "./txt/КР130.txt\n",
      "./txt/КР92.txt\n",
      "./txt/КР6.txt\n",
      "./txt/КР497.txt\n",
      "./txt/КР332.txt\n",
      "./txt/КР291.txt\n",
      "./txt/КР285.txt\n",
      "./txt/КР278.txt\n",
      "./txt/КР250.txt\n",
      "./txt/КР293.txt\n",
      "./txt/КР287.txt\n",
      "./txt/КР318.txt\n",
      "./txt/КР330.txt\n",
      "./txt/КР495.txt\n",
      "./txt/КР4.txt\n",
      "./txt/КР132.txt\n",
      "./txt/КР47.txt\n",
      "./txt/КР52.txt\n",
      "./txt/КР46.txt\n",
      "./txt/КР133.txt\n",
      "./txt/КР127.txt\n",
      "./txt/КР91.txt\n",
      "./txt/КР286.txt\n",
      "./txt/КР292.txt\n",
      "./txt/КР245.txt\n",
      "./txt/КР537.txt\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import re\n",
    "\n",
    "labels = []\n",
    "sentences = []\n",
    "for file in glob.glob('./txt/*.txt', recursive=True):\n",
    "    header =\"\"\n",
    "    print(file)\n",
    "    with open(file, 'r') as f:\n",
    "        count = 0\n",
    "        sents = re.split(r'\\.\\s', f.read())\n",
    "        for sentence in sents:\n",
    "            if \"Краткая информация\" in sentence:\n",
    "                header = 0\n",
    "            elif \"Диагностика\" in sentence:\n",
    "                header = 1\n",
    "            elif \"Лечение\" in sentence:\n",
    "                header = 2\n",
    "            elif \"Реабилитация\" in sentence:\n",
    "                header = 3\n",
    "            elif \"Профилактика\" in sentence:\n",
    "                header = 4\n",
    "            if header != '':\n",
    "                labels.append(header)\n",
    "                sentences.append(sentence.replace('\\n', ' '))\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "advised-guyana",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from collections import defaultdict\n",
    "from nltk.corpus import wordnet as wn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import model_selection, naive_bayes, svm\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "hungry-pleasure",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from pymystem3 import Mystem\n",
    "from string import punctuation\n",
    "\n",
    "mystem = Mystem() \n",
    "russian_stopwords = stopwords.words(\"russian\")\n",
    "\n",
    "#Preprocess function\n",
    "def preprocess_text(text):\n",
    "    text = re.sub(\"\\d+\", \" \", text)\n",
    "    tokens = mystem.lemmatize(text.lower())\n",
    "    tokens = [token for token in tokens if token not in russian_stopwords and token not in ['уровень','пациент','рекомендация']\\\n",
    "              and token != \" \" \\\n",
    "              and token.strip() not in punctuation]\n",
    "    \n",
    "    \n",
    "    \n",
    "    return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "qualified-thought",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed = []\n",
    "for sentence in sentences:\n",
    "    processed.append(preprocess_text(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "viral-matrix",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_X, Test_X, Train_Y, Test_Y = model_selection.train_test_split(processed, labels, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cutting-direction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(max_features=5000)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tfidf_vect = TfidfVectorizer(max_features=5000)\n",
    "Tfidf_vect.fit(sentences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "advance-advice",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_X_Tfidf = Tfidf_vect.transform(Train_X)\n",
    "Test_X_Tfidf = Tfidf_vect.transform(Test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "extended-laugh",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy Score ->  61.66861764392891\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.69      0.60      2417\n",
      "           1       0.53      0.65      0.59      3479\n",
      "           2       0.90      0.58      0.70     11710\n",
      "           3       0.15      0.96      0.27       141\n",
      "           4       0.26      0.75      0.39      1047\n",
      "\n",
      "    accuracy                           0.62     18794\n",
      "   macro avg       0.48      0.72      0.51     18794\n",
      "weighted avg       0.74      0.62      0.65     18794\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# fit the training dataset on the NB classifier\n",
    "Naive = naive_bayes.MultinomialNB()\n",
    "Naive.fit(Train_X_Tfidf,Train_Y)\n",
    "# predict the labels on validation dataset\n",
    "predictions_NB = Naive.predict(Test_X_Tfidf)\n",
    "# Use accuracy_score function to get the accuracy\n",
    "print(\"Naive Bayes Accuracy Score -> \",accuracy_score(predictions_NB, Test_Y)*100)\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(predictions_NB, Test_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "yellow-calvin",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy Score ->  64.49398744280089\n"
     ]
    }
   ],
   "source": [
    "# Classifier - Algorithm - SVM\n",
    "# fit the training dataset on the classifier\n",
    "SVM = svm.SVC(C=1.0, kernel='linear', degree=3, gamma='auto')\n",
    "SVM.fit(Train_X_Tfidf,Train_Y)\n",
    "# predict the labels on validation dataset\n",
    "predictions_SVM = SVM.predict(Test_X_Tfidf)\n",
    "# Use accuracy_score function to get the accuracy\n",
    "print(\"SVM Accuracy Score -> \",accuracy_score(predictions_SVM, Test_Y)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "incredible-henry",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.62      0.64      3355\n",
      "           1       0.55      0.67      0.60      3538\n",
      "           2       0.85      0.63      0.72     10078\n",
      "           3       0.37      0.91      0.53       359\n",
      "           4       0.34      0.71      0.46      1464\n",
      "\n",
      "    accuracy                           0.64     18794\n",
      "   macro avg       0.55      0.71      0.59     18794\n",
      "weighted avg       0.71      0.64      0.66     18794\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(predictions_SVM, Test_Y))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
